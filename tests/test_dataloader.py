import torch
import os
import sys
from torch.utils.data import DataLoader
from PIL import Image

# å°è¯•å¼•å…¥ diffsynth åº“
try:
    from diffsynth.core import UnifiedDataset
    from diffsynth.core.data.operators import LoadVideo, LoadAudio, ToAbsolutePath
except ImportError:
    print("âŒ é”™è¯¯: æ‰¾ä¸åˆ° diffsynth åº“ï¼Œè¯·ç¡®ä¿çŽ¯å¢ƒå˜é‡è®¾ç½®æ­£ç¡®ã€‚")
    exit()

# ==========================================
# 1. é…ç½®åŒºåŸŸ (åŸºäºŽä½ çš„çœŸå®žçŽ¯å¢ƒ)
# ==========================================
class MockArgs:
    def __init__(self):
        # [çœŸå®žè·¯å¾„]
        self.dataset_base_path = "/baai-cwm-vepfs/cwm/cheng.li/liutong/MM-AU/full_demos"
        self.dataset_geometry_path = "/baai-cwm-backup/cwm/tong.liu/Geo_Out"
        self.dataset_metadata_path = "/baai-cwm-vepfs/cwm/cheng.li/liutong/MM-AU/metadata.csv"
        
        # [è§†é¢‘å‚æ•°]
        self.height = 480
        self.width = 832
        self.num_frames = 49
        
        # Resize å‚æ•° (é€šå¸¸ä¿æŒé»˜è®¤æˆ–æ ¹æ®æ˜¾å­˜è°ƒæ•´)
        self.max_pixels = 512 * 512 
        
        # æ•°æ®é›†å‚æ•°
        self.dataset_repeat = 1
        self.data_file_keys = "video" 

args = MockArgs()

# ==========================================
# 2. ä¸»æµ‹è¯•é€»è¾‘
# ==========================================
def test_dataloader_final():
    print(f"ðŸš€ å¼€å§‹æµ‹è¯• DataLoader (Metadata æ¨¡å¼)...")
    print(f"ðŸ“‚ Video Path: {args.dataset_base_path}")
    print(f"ðŸ“‚ Geo Path:   {args.dataset_geometry_path}")
    print(f"ðŸ“„ Metadata:   {args.dataset_metadata_path}")

    # 1. åˆå§‹åŒ– UnifiedDataset
    # è¿™æ¬¡æˆ‘ä»¬ä¼šä¼ å…¥ metadata_pathï¼Œè®©å®ƒè‡ªå·±åŽ»è¯» CSV
    try:
        dataset = UnifiedDataset(
            base_path=args.dataset_base_path,
            geometry_path=args.dataset_geometry_path, # [ä½ çš„ Depth ä»£ç ç”Ÿæ•ˆå¤„]
            metadata_path=args.dataset_metadata_path, # [è¯»å– CSV]
            
            # å°ºå¯¸å‚æ•°
            height=args.height,
            width=args.width,
            num_frames=args.num_frames,
            
            repeat=args.dataset_repeat,
            data_file_keys=args.data_file_keys.split(","),
            
            # è§†é¢‘åŠ è½½ç®—å­ (åªåš Resize, ä¸è½¬ Tensor)
            main_data_operator=UnifiedDataset.default_video_operator(
                base_path=args.dataset_base_path,
                max_pixels=args.max_pixels,
                height=args.height,
                width=args.width,
                num_frames=args.num_frames,
            ),
        )
        print(f"âœ… Dataset åˆå§‹åŒ–æˆåŠŸï¼Œæ€»æ•°æ®é‡: {len(dataset)}")
        
    except Exception as e:
        print(f"âŒ Dataset åˆå§‹åŒ–å¤±è´¥: {e}")
        # å¸¸è§é”™è¯¯æç¤º
        if "No such file" in str(e):
            print("   -> è¯·æ£€æŸ¥ metadata.csv æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®ã€‚")
        return

    # 2. åˆå§‹åŒ– DataLoader
    # ã€å…³é”®ã€‘collate_fn=lambda x: x[0]
    # æ„å‘³ç€ DataLoader å–å‡ºä¸€ä¸ªæ ·æœ¬åŽï¼Œç›´æŽ¥æŠŠè¯¥æ ·æœ¬(dict)ä¼ å‡ºæ¥ï¼Œä¸è¿›è¡Œä»»ä½• Tensor æ‰“åŒ…
    dataloader = DataLoader(
        dataset, 
        batch_size=1, 
        shuffle=False, 
        num_workers=0, 
        collate_fn=lambda x: x[0] 
    )

    print("\nðŸ”„ å¼€å§‹è¯»å–å‰ 2 ä¸ªæ ·æœ¬...")
    
    try:
        for i, batch in enumerate(dataloader):
            if i >= 2: break
            
            print(f"\n--- Sample {i} ---")
            # æ­¤æ—¶ batch å°±æ˜¯ä¸€ä¸ªæ™®é€šçš„ python dict
            
            # æ£€æŸ¥ Video (é¢„æœŸ: List of PIL)
            if "video" in batch:
                video_data = batch["video"]
                print(f"  ðŸŽ¬ Key: 'video'")
                print(f"     Type: {type(video_data)}") # <class 'list'>
                
                if isinstance(video_data, list) and len(video_data) > 0:
                    first_frame = video_data[0]
                    print(f"     Content: List of {type(first_frame)}") # <class 'PIL.Image.Image'>
                    print(f"     Length: {len(video_data)} frames")
                    # PIL size æ˜¯ (Width, Height)
                    print(f"     Size: {first_frame.size} (Expected: ({args.width}, {args.height}))")
            
            # æ£€æŸ¥ Depth (é¢„æœŸ: Tensor)
            if "depth" in batch:
                depth_data = batch["depth"]
                print(f"  ðŸ§Š Key: 'depth'")
                print(f"     Type: {type(depth_data)}") # <class 'torch.Tensor'>
                
                if isinstance(depth_data, torch.Tensor):
                    print(f"     Shape: {depth_data.shape}") 
                    # é¢„æœŸ: [1, 1, 49, 480, 832] (å¦‚æžœä½ çš„ä»£ç å¸¦batch dim) 
                    # æˆ–è€… [1, 49, 480, 832] (å¦‚æžœä½ çš„ä»£ç ä¸å¸¦batch dim)
                    
                    print(f"     Range: min={depth_data.min():.2f}, max={depth_data.max():.2f}")
                    
                    # ç®€å•éªŒè¯ä¸€ä¸‹æ•°å€¼æ˜¯å¦åˆç†
                    if depth_data.max() > 1.1 or depth_data.min() < -1.1:
                        print("     âš ï¸ è­¦å‘Š: Depth æ•°å€¼èŒƒå›´ä¼¼ä¹Žæ²¡æœ‰å½’ä¸€åŒ–åˆ° [-1, 1]")
                    else:
                        print("     âœ… æ•°å€¼èŒƒå›´æ­£å¸¸ (Normalized)")

            # æ£€æŸ¥ Prompt
            if "prompt" in batch:
                print(f"  ðŸ“ Key: 'prompt' | Content: {str(batch['prompt'])[:50]}...")

    except Exception as e:
        import traceback
        print("\nâŒ è¿­ä»£è¿‡ç¨‹æŠ¥é”™:")
        traceback.print_exc()

    print("\nâœ… æµ‹è¯•ç»“æŸã€‚")

if __name__ == "__main__":
    test_dataloader_final()